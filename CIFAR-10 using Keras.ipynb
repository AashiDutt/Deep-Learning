{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this repository we look trough the CIFAR-10 dataset using Keras \n",
    "\n",
    "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class\n",
    "\n",
    "\n",
    "CIFAR-10 is a set of images that can be used to teach a computer how to recognize objects. Since the images in CIFAR-10 are low-resolution (32x32), this dataset can allow researchers to quickly try different algorithms to see what works. Various kinds of convolutional neural networks tend to be the best at recognizing the images in CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import sys\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend   as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# Any results you write to the cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key='labels'):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    # Arguments\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    # Returns\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, 'rb') as f:\n",
    "        if sys.version_info < (3,):\n",
    "            d = pickle.load(f)\n",
    "        else:\n",
    "            d = pickle.load(f, encoding='bytes')\n",
    "            # decode utf8\n",
    "            d_decoded = {}\n",
    "            for k, v in d.items():\n",
    "                d_decoded[k.decode('utf8')] = v\n",
    "            d = d_decoded\n",
    "    data = d['data']\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 50000\n",
    "train_x = np.zeros(shape=(train_num,3,32,32))\n",
    "train_y = np.zeros(shape=(train_num))\n",
    "\n",
    "test_num = 10000\n",
    "test_x = np.zeros(shape=(test_num,3,32,32))\n",
    "test_y = np.zeros(shape=(test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    for i in range(1,6):\n",
    "        begin = (i-1)*10000\n",
    "        end = i*10000\n",
    "        train_x[begin:end,:,:,:],train_y[begin:end] = load_batch(\"../input/cifar-10-python/cifar-10-batches-py/data_batch_\"+str(i))\n",
    "    \n",
    "    test_x[:],test_y[:] = load_batch(\"../input/cifar-10-python/cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_last':\n",
    "    print(\"channels_last\")\n",
    "    test_x = test_x.transpose(0, 2, 3, 1)\n",
    "    train_x = train_x.transpose(0, 2, 3, 1)\n",
    "else:\n",
    "    print(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "train_x = train_x/255.0\n",
    "test_x = test_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y,10)\n",
    "test_y = to_categorical(test_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=train_x.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 266s 5ms/step - loss: 2.1621 - acc: 1.0000 - val_loss: 2.0247 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 403s 8ms/step - loss: 1.8915 - acc: 1.0000 - val_loss: 1.7601 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 424s 8ms/step - loss: 1.6337 - acc: 1.0000 - val_loss: 1.5097 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 433s 9ms/step - loss: 1.3917 - acc: 1.0000 - val_loss: 1.2764 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 419s 8ms/step - loss: 1.1680 - acc: 1.0000 - val_loss: 1.0629 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 425s 9ms/step - loss: 0.9653 - acc: 1.0000 - val_loss: 0.8713 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 434s 9ms/step - loss: 0.7854 - acc: 1.0000 - val_loss: 0.7033 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 435s 9ms/step - loss: 0.6293 - acc: 1.0000 - val_loss: 0.5592 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 391s 8ms/step - loss: 0.4971 - acc: 1.0000 - val_loss: 0.4386 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.3876 - acc: 1.0000 - val_loss: 0.3399 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 266s 5ms/step - loss: 0.2988 - acc: 1.0000 - val_loss: 0.2606 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.2281 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 267s 5ms/step - loss: 0.1728 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 265s 5ms/step - loss: 0.1301 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.0975 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "22944/50000 [============>.................] - ETA: 3:40 - loss: 0.0786 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-89dd8c36d014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_y,batch_size,epochs,validation_data=(test_x,test_y),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histroy.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.plot(history.history[\"acc\"],label = \"train\", color='green')\n",
    "plt.plot(history.history[\"val_acc\"],label = \"test\", color='red')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy by epochs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
